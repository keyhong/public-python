{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227468b-4dc7-4f74-a6a1-7ddd2ff6f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in *.deb; do   dpkg-deb -x \"$file\" /home/cdsw/inst; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e0889-1874-491c-8471-b77f094a9242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01931c5-3fa4-406d-815d-f6932295f9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22dc58-1ac3-413d-8a6b-9e6a5af5e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt-get install -y --no-install-recommends --download-only tree\n",
    "mv /var/cache/apt/archives/*.deb /home/cdsw/packages/ubuntu_packages/tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9c7c6-9ea4-406f-83a7-24d05d1e0bda",
   "metadata": {},
   "source": [
    "# Powerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cff13-35e2-47de-b571-e8f87e6c42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt-cache depends pandoc texlive-xetex texlive-fonts-recommended texlive-plain-generic | grep \"Depends\" | awk '{print $2}' | xargs apt-get download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e484e-ede8-4662-b0a8-7d86df6d4011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e820a3-089a-4ca6-ae09-c6dd361def88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts-powerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6776a66-9de4-41f1-87ca-32ece81749d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6a28b-200d-4d71-91ab-32de9c922abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt-get install -y --no-install-recommends --download-only fonts-powerline\n",
    "mv /var/cache/apt/archives/*.deb ${JUPYTER_SERVER_ROOT}/packages/ubuntu_packages/fonts-powerline\n",
    "rm -rf /var/cache/apt/archives\n",
    "\n",
    "apt-get install -y --no-install-recommends --download-only powerline\n",
    "mv /var/cache/apt/archives/*.deb ${JUPYTER_SERVER_ROOT}/packages/ubuntu_packages/powerline\n",
    "rm -rf /var/cache/apt/archives\n",
    "\n",
    "apt-get  --print-uris --yes --no-install-recommends install \\\n",
    "    pandoc texlive-xetex texlive-fonts-recommended texlive-plain-generic\n",
    "mv /var/cache/apt/archives/*.deb ${JUPYTER_SERVER_ROOT}/packages/ubuntu_packages/powerline\n",
    "rm -rf /var/cache/apt/archives\n",
    "\n",
    "apt-get install -y --no-install-recommends --download-only vim\n",
    "mv /var/cache/apt/archives/*.deb ${JUPYTER_SERVER_ROOT}/packages/ubuntu_packages/vim\n",
    "rm -rf /var/cache/apt/archives\n",
    "\n",
    "apt-get install -y --no-install-recommends --download-only bash-completion\n",
    "mv /var/cache/apt/archives/*.deb ${JUPYTER_SERVER_ROOT}/packages/ubuntu_packages/bash-completion\n",
    "rm -rf /var/cache/apt/archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99c56d-746e-4f1a-98b0-2bf17654e2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00f5cf-7825-41c6-af23-b34881eb153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt-get install -y --no-install-recommends --download-only python3-dev\n",
    "mv /var/cache/apt/archives/*.deb ${JUPYTER_SERVER_ROOT}/packages/ubuntu_packages/python3-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ea6eb-2204-442c-8598-f76732532755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab444bc-b54f-4fcb-af3c-35a7660f045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt-get install -y --no-install-recommends --download-only pandoc texlive-xetex texlive-fonts-recommended texlive-plain-generic\n",
    "mv /var/cache/apt/archives/*.deb ${JUPYTER_SERVER_ROOT}/packages/ubuntu_packages/common/pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27340d-61fd-46f1-bb14-3cd4582054cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc536c8c-bd1c-4598-8a5c-f8a1ca260cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30cd324-7cec-4ba1-901c-add03c548321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c907c4-f14f-4f84-8a22-1ea0a28e4d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c91f3-012a-4bf0-ad18-eecea7552bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt-get install -y --no-install-repcommends --download-only compaudit \n",
    "mv /var/cache/apt/archives/*.deb ${JUPYTER_SERVER_ROOT}/packages/ubuntu_packages/common/compaudit \n",
    "\n",
    "chmod 755 /usr/share/zsh/functions\n",
    "chmod 755 /usr/share/zsh/functions/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b67a9d-8600-4fcb-a311-bcade10d3f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "445ff83d-0f94-4374-81e9-66dacc903a33",
   "metadata": {},
   "source": [
    "apt-get install -y --no-install-recommends --download-only pandoc texlive-xetex texlive-fonts-recommended texlive-plain-generic\n",
    "cp /var/cache/apt/archives/*.deb /home/cdsw/ubuntu_packages/pandoc\n",
    "\n",
    "apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic\n",
    "\n",
    "apt-get install -y --no-install-recommends pandoc texlive-xetex texlive-fonts-recommended texlive-plain-generic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f6f3b7-ecba-4e2f-b97b-6d066dd87d17",
   "metadata": {},
   "source": [
    "import pyodbc\n",
    "\n",
    "cd /var/cache/apt/archives/\n",
    "\n",
    "apt-get updatemM\n",
    "apt-get install unixodbc-dev\n",
    "apt-get install -y --no-install-recommends --download-only unixodbc-dev\n",
    "cp /var/cache/apt/archives/*.deb /home/cdsw/ubuntu_packages\n",
    "dpkg -i *.deb\n",
    "\n",
    "! pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71f667-e334-4f6f-bf5b-6ad3430dc0c7",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449bee6f-aa93-4c1b-a2fe-eda3c4e4088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import dateutil.relativedelta\n",
    "import matplotlib\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import pandas\n",
    "import requests\n",
    "import six\n",
    "import urllib3\n",
    "import yaml\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython import get_ipython\n",
    "# from IPython.core.display import display => from IPython.display import display\n",
    "from IPython.display import display\n",
    "\"\"\"\n",
    "/tmp/ipykernel_70/812137715.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
    "  from IPython.core.display import display\n",
    "\"\"\"  \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import IFrame\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame, Series\n",
    "from pandas.compat.pickle_compat import _class_locations_map\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from PIL import Image\n",
    "from pytz import timezone, utc\n",
    "from requests import get\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d92375-ebd1-4260-8498-f3af874c28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import GBTClassifier, GBTClassificationModel, RandomForestClassifier, RandomForestClassificationModel\n",
    "from pyspark.ml.feature import MinMaxScaler, OneHotEncoder, StringIndexer, StringIndexerModel, Tokenizer, VectorAssembler\n",
    "from pyspark.ml.fpm import FPGrowth, FPGrowthModel\n",
    "from pyspark.sql import HiveContext, SparkSession, DataFrame, types, Window, functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25231164-86f7-4e44-bc98-f3def93ccec5",
   "metadata": {},
   "source": [
    "# 2. User Install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d985947-8751-4ef8-8945-31ac5f41b63e",
   "metadata": {},
   "source": [
    "## 2-0. visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a091ae-74f0-4098-bc49-c19112414194",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install seaborn\n",
    "\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322895ba-ddfa-4126-98a8-087741a91727",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306c1cd6-2703-4703-9d7f-f96a28e56516",
   "metadata": {},
   "source": [
    "## 2-1. Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7464c-a85d-467d-b838-c6eb4f2d469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "import pyarrow.compute\n",
    "import pyarrow.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ce68d-dd4c-43d3-b4b4-e24da61df774",
   "metadata": {},
   "source": [
    "## 2-2. Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26771a-b379-4fee-b8fc-29be97ef2eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d719cf-d156-42a5-9600-5a3bedf71c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow[and-cuda]==2.17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1966c4c-2f23-4b1c-a6f5-eaed67369998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "# from tensorflow.contrib.nccl.python.ops import nccl_ops\n",
    "from tensorflow.python.ops import nccl_ops\n",
    "\"\"\"No module named 'tensorflow.contrib'\n",
    "=> from tensorflow.python.ops import nccl_ops\n",
    "\"\"\"\n",
    "from tensorflow.keras import Model, Sequential, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa924ebd-8892-48e6-8eaa-54ab40fbea30",
   "metadata": {},
   "source": [
    "## 2-3. Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f3b67-7c9e-4b42-9827-3c59e228ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip download torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9758cf83-b16e-4a1a-8c96-366dd01e0fb0",
   "metadata": {},
   "source": [
    "! pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f52c7af-8674-4797-a4a8-2c606e049d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      " 32%|███▏      | 31.0M/97.8M [00:03<00:07, 9.40MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResNet50_Weights\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_zoo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_url \u001b[38;5;28;01mas\u001b[39;00m load_state_dict_from_url\n\u001b[0;32m---> 26\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mResNet50_Weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGENET1K_V2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/hub.py:867\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    865\u001b[0m         r \u001b[38;5;241m=\u001b[39m HASH_REGEX\u001b[38;5;241m.\u001b[39msearch(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         hash_prefix \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/hub.py:744\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[1;32m    737\u001b[0m     total\u001b[38;5;241m=\u001b[39mfile_size,\n\u001b[1;32m    738\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m progress,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    741\u001b[0m     unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m    742\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m         buffer \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_DATA_CHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    746\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/http/client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/http/client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn\n",
    "import torch.nn\n",
    "import torch.utils.data\n",
    "import torchvision.transforms\n",
    "\n",
    "from torch import BoolTensor, Tensor, nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import AvgPool1d, Conv1d, Conv2d, ConvTranspose1d, Parameter\n",
    "from torch.nn import Embedding, Linear, ModuleList, ReLU, Sequential, functional\n",
    "from torch.nn.utils import remove_weight_norm, spectral_norm, weight_norm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import models\n",
    "# from torchvision.models.vgg import model_urls\n",
    "\"\"\"cannot import name 'model_urls' from 'torchvision.models.vgg' (/usr/local/lib/python3.11/site-packages/torchvision/models/vgg.py)\n",
    "=> \n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "\n",
    "checkpoint = load_state_dict_from_url(ResNet50_Weights.IMAGENET1K_V2.url)\n",
    "\"\"\"\n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "checkpoint = load_state_dict_from_url(ResNet50_Weights.IMAGENET1K_V2.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b34b1f-bee0-4f3e-9a09-8cf192715c7d",
   "metadata": {},
   "source": [
    "## 2-4. scikit-learn or Etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f15695-216c-465b-aeaf-af68fe24e2d6",
   "metadata": {},
   "source": [
    "! pip install catboost lightgbm xgboost scikit-learn lightfm tslearn\n",
    "! pip install dask[dataframe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f288a-a15e-47dd-a78e-973f1b691006",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip download --no-deps catboost\n",
    "! pip download --no-deps lightgbm\n",
    "! pip download --no-deps xgboost\n",
    "! pip download --no-deps scikit-learn\n",
    "! pip download --no-deps skope-rules\n",
    "! pip download --no-deps lightfm\n",
    "! pip download --no-deps tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793751de-414d-4734-9dfa-991d9badfd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps threadpoolctl\n",
    "! pip install --no-deps numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dbcc7ba-9f95-4aeb-92cd-7c0144652fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier, plot_importance\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from sklearn.base import clone\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_curve, make_scorer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ShuffleSplit, train_test_split, cross_val_predict\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, label_binarize, StandardScaler\n",
    "from sklearn.utils import gen_batches\n",
    "\n",
    "import collections.abc\n",
    "import six\n",
    "import sklearn\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "sklearn.externals.six = six\n",
    "from skrules import SkopeRules\n",
    "\"\"\"cannot import name 'Iterable' from 'collections' (/usr/local/lib/python3.11/collections/__init__.py)\n",
    "=>\n",
    "import collections.abc\n",
    "import six\n",
    "import sklearn\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "sklearn.externals.six = six\n",
    "from skrules import SkopeRules\n",
    "\"\"\"\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "\n",
    "from tslearn.clustering import KShape, TimeSeriesKMeans\n",
    "from tslearn.generators import random_walks\n",
    "from tslearn.metrics import cdist_dtw\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn.utils import to_time_series, to_time_series_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc36ad-61f6-49d3-80e6-7a6f4a297caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9f4a33c-f7e4-475a-be69-1b2978b4b81b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fairseq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models, utils, hub_utils\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcriterions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FairseqCriterion, register_criterion\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dictionary\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fairseq'"
     ]
    }
   ],
   "source": [
    "from fairseq import models, utils, hub_utils\n",
    "from fairseq.criterions import FairseqCriterion, register_criterion\n",
    "from fairseq.data import Dictionary\n",
    "from fairseq.data.encoders import register_bpe\n",
    "from fairseq.data.encoders.gpt2_bpe import get_encoder\n",
    "from fairseq.models import FairseqEncoder\n",
    "from fairseq.models.roberta import RobertaClassificationHead, RobertaLMHead, RobertaHubInterface, RobertaModel\n",
    "from fairseq.models.roberta.hub_interface import RobertaHubInterface\n",
    "from fairseq.models.transformer import TransformerModel\n",
    "from fairseq.modules import TransformerSentenceEncoder\n",
    "from fairseq.modules.transformer_sentence_encoder import init_bert_params\n",
    "from fairseq.tasks import FairseqTask, register_task\n",
    "from fairseq.tasks.audio_pretraining import AudioPretrainingTask\n",
    "\n",
    "\"\"\"\n",
    "ValueError: mutable default <class 'fairseq.dataclass.configs.CommonConfig'> for field common is not allowed: use default_factory\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6d493-0483-460e-91c1-4d274ce11c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abf38a0-1861-482f-b7fe-ff97fa96345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram, to_tree, cut_tree\n",
    "from scipy.signal import lfilter\n",
    "from scipy.sparse import coo_matrix, hstack, vstack\n",
    "# from scipy.spatial import distance, rel_entr => (underline)\n",
    "from scipy.spatial import distance\n",
    "from scipy.special import rel_entr\n",
    "\"\"\"\n",
    "cannot import name 'rel_entr' from 'scipy.spatial' (/usr/local/lib/python3.11/site-packages/scipy/spatial/__init__.py)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from scipy.stats import skew, zmap, zscore\n",
    "from scipy import sparse, spatial, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af3e2a-69a7-4d5c-a869-b20a201c2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "381c81b5-efa5-4e00-a93d-8f0ccad27604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa import arima_model\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42c255-6a0e-4934-a2f3-c2a6e7529be4",
   "metadata": {},
   "source": [
    "### Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d017c-6306-4570-ac82-a677ee1e3dcc",
   "metadata": {},
   "source": [
    "#### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bc494-5764-4a41-8415-bdc43f8b8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6940df3d-6b41-40b1-8720-ba56bca88c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc76e7-09df-4d0d-ab71-090556c287dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff40bbf2-1ba2-4579-bedc-a2ac17a56162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897512c1-fe20-4af9-94d7-070aab6bf546",
   "metadata": {},
   "source": [
    "#### Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e01f04-7762-4ac1-aa36-bcbf0eb82759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install --no-deps soundfile\n",
    "! pip install --no-deps epitran\n",
    "! pip install --no-deps librosa\n",
    "! pip install --no-deps pydub\n",
    "! pip install --no-deps panphon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cdc475b-dfeb-42f2-804f-2acae5e9f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import soundfile\n",
    "\n",
    "# import epitran\n",
    "\n",
    "import librosa\n",
    "import librosa.effects\n",
    "import librosa.feature\n",
    "\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8be92-08e6-4e0e-b19a-3ad8a3e185fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps wav2letter\n",
    "\n",
    "from wav2letter.criterion import CpuViterbiPath, get_data_ptr_as_bytes\n",
    "from wav2letter.decoder import CriterionType\n",
    "\n",
    "\"\"\"\n",
    "ERROR: Could not find a version that satisfies the requirement wav2letter (from versions: none)\n",
    "ERROR: No matching distribution found for wav2letter\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bd2c7-c469-4c51-b58b-a2e07435b6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "927b23f9-0636-44a1-9c0c-b50f90c41494",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48daf590-fc11-401f-b1d6-7f5243af32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps g2p_en\n",
    "! pip install --no-deps nltk\n",
    "! pip install --no-deps g2pk\n",
    "! pip install --no-deps kss\n",
    "! pip install --no-deps konlpy\n",
    "! pip install --no-deps ko_pron\n",
    "! pip install --no-deps koparadigm\n",
    "! pip install --no-deps fasttext\n",
    "! pip install --no-deps word2word\n",
    "! pip install --no-deps sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13844d73-e966-49d6-9ab7-9093b3687026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a90bb6ea-00d9-45e1-a855-2ae861261791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# transformers => from torch.optim import AdamW\n",
    "# from transformers import AdamW\n",
    "from transformers import AlbertForSequenceClassification\n",
    "# from transformers import AlbertModel\n",
    "from transformers import TFAlbertModel\n",
    "from transformers import BertConfig\n",
    "# from transformers import BertModel\n",
    "from transformers import BertJapaneseTokenizer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import InputExample\n",
    "from transformers import InputFeatures\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import PreTrainedTokenizer\n",
    "from transformers import RobertaModel\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a431b466-03a2-46b3-b91f-2dbd3f24c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers\n",
    "# from transformers import AdamW, AlbertForSequenceClassification, AlbertModel, TFAlbertModel, BertConfig, BertModel, BertJapaneseTokenizer, BertTokenizer, InputExample, InputFeatures\n",
    "from transformers import AlbertForSequenceClassification, AlbertModel, TFAlbertModel, BertConfig, BertModel, BertJapaneseTokenizer, BertTokenizer, InputExample, InputFeatures\n",
    "from torch.optim import AdamW\n",
    "\"\"\"cannot import name 'AdamW' from 'transformers' \n",
    "=> from torch.optim import AdamW\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, PreTrainedTokenizer, RobertaModel, RobertaTokenizer\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c888606f-758c-4ce8-8ad6-701bc2d081fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno -2] Name or service not known>\n",
      "[nltk_data] Error loading cmudict: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n",
      "[nltk_data] Error loading cmudict: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "# tokenizers\n",
    "from tokenizers.models import BPE, Unigram\n",
    "from tokenizers.normalizers import NFKC\n",
    "from tokenizers import Tokenizer, decoders, pre_tokenizers\n",
    "from tokenizers.implementations import BaseTokenizer\n",
    "\n",
    "# english\n",
    "from g2p_en import G2p\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# korea\n",
    "from g2pk import G2p\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "from kss import split_sentences\n",
    "\n",
    "# all\n",
    "import fasttext\n",
    "\n",
    "from word2word import Word2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f692e18a-428e-418d-a0a8-148a7959a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers\n",
    "! pip install tokenizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55277a1f-1aed-4797-aa53-74f0d9b678ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff82da-a955-42e6-80d6-608e027a28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps jamo\n",
    "! pip install --no-deps kollocate\n",
    "! pip install --no-deps jieba\n",
    "! pip install --no-deps fugashi\n",
    "! pip install --no-deps ipadic\n",
    "! pip install --no-deps romkan\n",
    "! pip install --no-deps g2pM\n",
    "! pip install --no-deps mecab\n",
    "! pip install --no-deps sentencepiece\n",
    "! pip install --no-deps sacremoses\n",
    "! pip install --no-deps python-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ca93f-15c0-45a7-95df-c94c4a4d8882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "315fe212-a47a-4ddc-afd1-6a7f058d41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# korea\n",
    "from jamo import h2j, j2hcj, j2h\n",
    "from ko_pron import romanise\n",
    "from kollocate import Kollocate\n",
    "# from koparadigm import Paradigm\n",
    "\"\"\"XLRDError: Excel xlsx file; not supported\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# china\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "\n",
    "# japan\n",
    "import fugashi\n",
    "import ipadic\n",
    "import romkan\n",
    "\n",
    "# all\n",
    "from g2pM import G2pM\n",
    "\n",
    "import mecab\n",
    "\n",
    "# tokenizers\n",
    "import sentencepiece\n",
    "\n",
    "from sacremoses import MosesDetokenizer, MosesTokenizer\n",
    "\n",
    "# model\n",
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d16fb8e-c55b-4dc3-98bc-b0be45da47b7",
   "metadata": {},
   "source": [
    "#### Geo Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575bb3a-a48d-46f1-bb36-a4830188f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps shapely\n",
    "! pip install --no-deps geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b8b13a-2f48-468e-ac12-2960e7347ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon, Point, LineString\n",
    "\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf46a9d-d627-45a1-8c3a-e80361fc6e25",
   "metadata": {},
   "source": [
    "#### Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63420cd8-0686-4f81-884f-19ee878aa115",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps html_table_extractor\n",
    "! pip install --no-deps joblib\n",
    "! pip install --no-deps wget\n",
    "! pip install --no-deps pyathena\n",
    "! pip install --no-deps whoosh\n",
    "! pip install --no-deps fastdtw\n",
    "! pip install --no-deps natsort\n",
    "! pip install --no-deps marisa_trie\n",
    "! pip install --no-deps tqdm\n",
    "! pip install --no-deps pyodbc\n",
    "! pip install --no-deps lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de9d08c6-0dfb-476d-a0bc-d26c3b24b801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlibodbc.so.2: cannot open shared object file: No such file or directory\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from html_table_extractor.extractor import Extractor\n",
    "\n",
    "import joblib\n",
    "\n",
    "import wget\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "from pyathena import connect\n",
    "from pyathena.pandas.util import to_sql\n",
    "\n",
    "from whoosh import index\n",
    "from whoosh.qparser import QueryParser\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "from natsort import natsorted\n",
    "\n",
    "from marisa_trie import RecordTrie, Trie\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import pyodbc\n",
    "\"\"\"\n",
    "libodbc.so.2: cannot open shared object file: No such file or directory\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820415a-c38c-46ea-be45-39a0d1deb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --no-deps umap-learn\n",
    "! pip install --no-deps gower\n",
    "! pip install --no-deps shap\n",
    "! pip install --no-deps pynndescent\n",
    "! pip install --no-deps xverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c88685-ab2f-488c-9dfb-ee374d793240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "import gower\n",
    "\n",
    "import shap\n",
    "\n",
    "import pynndescent\n",
    "\n",
    "from xverse.transformer import WOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde6f08-c271-4597-802d-4f8414c5f0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
